{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0f36763-c614-40b5-8e4a-e317d56ee834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\hanjh\\\\Desktop\\\\Kaggle project\\\\AB Testing'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()\n",
    "# os.chdir(default_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdacee1e-2caf-4ebd-ba41-6b1d02df0b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import mglearn\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, ParameterGrid, RepeatedKFold, StratifiedKFold, RepeatedStratifiedKFold, StratifiedKFold\n",
    "from iterstrat.ml_stratifiers import RepeatedMultilabelStratifiedKFold\n",
    "from sklearn.feature_selection import RFECV, VarianceThreshold, SelectFromModel\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, roc_auc_score, mean_squared_error, f1_score\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler, LabelBinarizer, label_binarize\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from imblearn.pipeline import Pipeline as Pipeline_imb\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV, LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import LinearSVC, SVC, SVR\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from summarytools import dfSummary\n",
    "from sklearn.metrics import roc_auc_score, RocCurveDisplay, precision_recall_curve\n",
    "from sklearn.model_selection import GridSearchCV, RepeatedStratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import classification_report, mean_squared_error, r2_score\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "import colorama\n",
    "from colorama import Fore, Style  # maakes strings colored\n",
    "# !pip3 install termcolor\n",
    "from termcolor import colored\n",
    "\n",
    "from warnings import simplefilter\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac7cdf09-bd23-4551-a008-0ca8806359af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "AB_df = pd.read_csv(\"cookie_cats.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43704682-156e-4b9f-81d6-edc7bbc4bf56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e5737d8a-1222-4e1e-b5de-47a5bda34d4c",
   "metadata": {},
   "source": [
    "## A/B Testing\n",
    "\n",
    "### Overview\n",
    "In A/B testing, choosing the right statistical test depends on the nature of your data, especially its distribution and variance.\n",
    "\n",
    "#### 1. Check for Normality\n",
    "First, determine if your data is normally distributed. You can use statistical tests like the Shapiro-Wilk test or visual tools like histograms or Q-Q plots to assess this. If the data is normally distributed, you can proceed with parametric tests like a t-test.\n",
    "\n",
    "#### 2. Parametric Test (t-test)\n",
    "Use the t-test (independent t-test) if:\n",
    "- Your data is normally distributed.\n",
    "- The variances between the two groups are equal (using Levene's test for equality of variances).\n",
    "- The two samples are independent of each other.\n",
    "\n",
    "##### Types of t-tests:\n",
    "- **Independent t-test**: Compare means between two independent groups (e.g., A and B).\n",
    "- **Paired t-test**: If you have repeated measurements from the same subjects (e.g., before and after tests on the same users).\n",
    "\n",
    "\n",
    "##### 2-1) Levene's Test and Welch's t-test\n",
    "\n",
    "In a parametric t-test, the Levene's test for equality of variances is performed to check if the two groups being compared have equal variances (homoscedasticity). This is important because the standard independent t-test assumes that the variances of the two groups are equal. \n",
    "\n",
    "##### Why Check for Equal Variances?\n",
    "##### Assumption of the Standard t-test\n",
    "The standard (Student's) t-test assumes that the two groups you're comparing have the same variance. \n",
    "If the variances of the two groups are not equal (heteroscedasticity), using the standard t-test can lead to inaccurate results. \n",
    "\n",
    "##### Levene's Test\n",
    "The Levene’s test checks whether the variances between the two groups are equal. \n",
    "If the test returns a p-value less than your significance level (e.g., 0.05), you can conclude that the variances are significantly different, and the assumption of equal variances is violated.\n",
    "\n",
    "##### What Happens if Variances Are Unequal?\n",
    "If Levene's test indicates that the variances are not equal, two options:\n",
    "\n",
    "1. **Use Welch’s t-test (an alternative to the standard t-test):**\n",
    "   - Welch's t-test is a version of the t-test that does not assume equal variances. It adjusts the degrees of freedom based on the variances of the two groups.\n",
    "   - This test is more reliable when the variances of the two groups are unequal and should be used whenever Levene’s test indicates unequal variances.\n",
    "\n",
    "2. **Proceed with caution using the standard t-test:**\n",
    "   - If you continue using the standard t-test despite unequal variances, your results may not be reliable, especially if the sample sizes are also unequal. The Welch’s t-test is always a safer choice in such cases.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b281ac26-546c-4e11-b2e4-c25cc4f693c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Levene’s test statistic: 12.346909938460435\n",
      "P-value from Levene's test: 0.0008636348956642888\n",
      "Reject the null hypothesis: Variances are not equal.\n",
      "Welch's t-test result: t-statistic = -2.6681938551004123, p-value = 0.0106543969626268\n"
     ]
    }
   ],
   "source": [
    "## Example: Levene's Test and Welch’s t-test in Python\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Sample data: Group A and Group B\n",
    "group_a = np.random.normal(loc=10, scale=2, size=30)  # Mean 10, SD 2\n",
    "group_b = np.random.normal(loc=12, scale=5, size=30)  # Mean 12, SD 5\n",
    "\n",
    "# Levene's Test for equality of variances\n",
    "stat, p_value = stats.levene(group_a, group_b)\n",
    "\n",
    "print(f\"Levene’s test statistic: {stat}\")\n",
    "print(f\"P-value from Levene's test: {p_value}\")\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(\"Reject the null hypothesis: Variances are not equal.\")\n",
    "    # Perform Welch’s t-test (does not assume equal variances)\n",
    "    t_stat, p_val_welch = stats.ttest_ind(group_a, group_b, equal_var=False)\n",
    "    print(f\"Welch's t-test result: t-statistic = {t_stat}, p-value = {p_val_welch}\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: Variances are equal.\")\n",
    "    # Perform standard t-test (assuming equal variances)\n",
    "    t_stat, p_val_ttest = stats.ttest_ind(group_a, group_b, equal_var=True)\n",
    "    print(f\"Standard t-test result: t-statistic = {t_stat}, p-value = {p_val_ttest}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db57773-32a9-4b17-9f17-eeaddd386569",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "54a799ae-fdf2-4116-b786-6fa9d92450c7",
   "metadata": {},
   "source": [
    "#### 3. Non-Parametric Test (Mann-Whitney U test)\n",
    "Use the Mann-Whitney U test (also called the Wilcoxon rank-sum test) if:\n",
    "- The data is not normally distributed.\n",
    "- The samples are independent of each other.\n",
    "- It tests for differences in the distribution between two groups.\n",
    "\n",
    "This test is a non-parametric alternative to the t-test when assumptions of normality are violated.\n",
    "\n",
    "#### 4. Chi-Square Test\n",
    "If your data is categorical (e.g., conversion rate: success/fail, clicks/no clicks), you might use a chi-square test to test for differences in proportions between the two groups.\n",
    "\n",
    "#### 5. Two-Proportion Z-test\n",
    "If you're comparing proportions between two groups (e.g., comparing conversion rates between group A and B), and both samples are large enough, you can use the two-proportion Z-test.\n",
    "\n",
    "##### Summary of Key Tests:\n",
    "- **Independent t-test**: Normally distributed data, comparing means.\n",
    "- **Paired t-test**: Repeated measures from the same group.\n",
    "- **Mann-Whitney U test**: Non-normally distributed data, comparing distributions.\n",
    "- **Chi-square test**: Categorical data.\n",
    "- **Two-proportion Z-test**: Large sample sizes, comparing proportions.\n",
    "\n",
    "#### How to Choose:\n",
    "- Start by checking if your data is normally distributed. If yes, go for the t-test.\n",
    "- If not, use the Mann-Whitney U test.\n",
    "- For categorical data, consider the chi-square test or Z-test for proportions.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee6248c-c357-4359-81c0-eade447c95cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8c899c5c-b3a2-42f4-b846-f0df13c209cd",
   "metadata": {},
   "source": [
    "#### Chi-Square Test Example\n",
    "\n",
    "##### Use Case: Comparing Categorical Data\n",
    "You would use the Chi-Square test when comparing categorical data between two groups. For example, you want to see if there's a significant difference in the click-through rates (CTR) between two different versions of a webpage (A and B).\n",
    "\n",
    "##### Scenario:\n",
    "- Group A (Control) has 200 users, 50 of whom clicked on an ad.\n",
    "- Group B (Variation) has 180 users, 70 of whom clicked on an ad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "229d72ac-f2e5-4db7-b6b9-7ac13f16cd36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi-Square Statistic: 7.82738425925926\n",
      "P-value: 0.005146051829425319\n",
      "Degrees of Freedom: 1\n",
      "Expected Frequencies: [[ 63.15789474 136.84210526]\n",
      " [ 56.84210526 123.15789474]]\n",
      "Reject the null hypothesis: There is a significant difference in click-through rates.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Contingency table\n",
    "data = np.array([[50, 150],  # Group A: 50 clicked, 150 did not click\n",
    "                 [70, 110]]) # Group B: 70 clicked, 110 did not click\n",
    "\n",
    "# Chi-Square Test\n",
    "chi2, p, dof, expected = stats.chi2_contingency(data)\n",
    "\n",
    "# Results\n",
    "print(f\"Chi-Square Statistic: {chi2}\")\n",
    "print(f\"P-value: {p}\")\n",
    "print(f\"Degrees of Freedom: {dof}\")\n",
    "print(f\"Expected Frequencies: {expected}\")\n",
    "\n",
    "# Interpretation\n",
    "if p < 0.05:\n",
    "    print(\"Reject the null hypothesis: There is a significant difference in click-through rates.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: No significant difference in click-through rates.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d38596-7a92-43ec-8150-29de5f8646ca",
   "metadata": {},
   "source": [
    "#### Two-Proportion Z-Test example\n",
    "Use the Two-Proportion Z-test when comparing proportions between two independent groups. This test is common in A/B testing for conversion rates or success rates.\n",
    "\n",
    "##### Scenario:\n",
    "\n",
    "Group A has 1000 users, 100 of whom converted (10% conversion rate).<br/>\n",
    "Group B has 1200 users, 150 of whom converted (12.5% conversion rate).<br/>\n",
    "You want to test if the conversion rate in Group B is significantly different from Group A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e3062c3b-8888-47d8-8413-94cb1bb8073c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z-Statistic: -1.839732422015599\n",
      "P-value: 0.06580753108398388\n",
      "Fail to reject the null hypothesis: No significant difference in conversion rates.\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# Data: Successes and Total Observations for both groups\n",
    "success_a = 100   # Conversions in Group A\n",
    "nobs_a = 1000     # Total users in Group A\n",
    "success_b = 150   # Conversions in Group B\n",
    "nobs_b = 1200     # Total users in Group B\n",
    "\n",
    "# Perform Two-Proportion Z-test\n",
    "count = np.array([success_a, success_b])\n",
    "nobs = np.array([nobs_a, nobs_b])\n",
    "\n",
    "zstat, pval = sm.stats.proportions_ztest(count, nobs)\n",
    "\n",
    "# Results\n",
    "print(f\"Z-Statistic: {zstat}\")\n",
    "print(f\"P-value: {pval}\")\n",
    "\n",
    "if pval < 0.05:\n",
    "    print(\"Reject the null hypothesis: The conversion rates are significantly different.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: No significant difference in conversion rates.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce09529e-5889-40e6-b2bc-a8bd55d3bca2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be1e079b-a847-417f-827c-fcf02dbdc90f",
   "metadata": {},
   "source": [
    "## Implement A/B Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d3fd9d6e-be20-4d22-bb93-5a585d434dff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userid</th>\n",
       "      <th>version</th>\n",
       "      <th>sum_gamerounds</th>\n",
       "      <th>retention_1</th>\n",
       "      <th>retention_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>116</td>\n",
       "      <td>gate_30</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>337</td>\n",
       "      <td>gate_30</td>\n",
       "      <td>38</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>377</td>\n",
       "      <td>gate_40</td>\n",
       "      <td>165</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>483</td>\n",
       "      <td>gate_40</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>488</td>\n",
       "      <td>gate_40</td>\n",
       "      <td>179</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userid  version  sum_gamerounds  retention_1  retention_7\n",
       "0     116  gate_30               3        False        False\n",
       "1     337  gate_30              38         True        False\n",
       "2     377  gate_40             165         True        False\n",
       "3     483  gate_40               1        False        False\n",
       "4     488  gate_40             179         True         True"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AB_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "cbaca17f-2f5f-434a-adc9-e60fb42a13a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normality Test (Shapiro-Wilk Test)\n",
      "gate_30: W-statistic=0.08805022308043553, p-value=2.146395844442685e-157\n",
      "gate_40: W-statistic=0.482561004889815, p-value=3.3446548187520663e-140\n",
      "At least one group is not normally distributed. Consider using a non-parametric test.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Split the data into two groups based on 'version'\n",
    "gate_30 = AB_df[AB_df['version'] == 'gate_30']['sum_gamerounds']\n",
    "gate_40 = AB_df[AB_df['version'] == 'gate_40']['sum_gamerounds']\n",
    "\n",
    "### 1. Check for Normality using Shapiro-Wilk Test\n",
    "print(\"Normality Test (Shapiro-Wilk Test)\")\n",
    "\n",
    "# Shapiro test for gate_30\n",
    "shapiro_gate_30 = stats.shapiro(gate_30)\n",
    "print(f\"gate_30: W-statistic={shapiro_gate_30[0]}, p-value={shapiro_gate_30[1]}\")\n",
    "\n",
    "# Shapiro test for gate_40\n",
    "shapiro_gate_40 = stats.shapiro(gate_40)\n",
    "print(f\"gate_40: W-statistic={shapiro_gate_40[0]}, p-value={shapiro_gate_40[1]}\")\n",
    "\n",
    "# Interpretation of Shapiro-Wilk Test\n",
    "if shapiro_gate_30[1] < 0.05 or shapiro_gate_40[1] < 0.05:\n",
    "    print(\"At least one group is not normally distributed. Consider using a non-parametric test.\")\n",
    "else:\n",
    "    print(\"Both groups appear normally distributed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "87752df3-83a4-4619-a1f4-906552640dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Variance Test (Levene's Test)\n",
      "Levene’s test statistic: 0.5292002638313259, p-value: 0.46694516772623273\n",
      "Variances are equal (homoscedasticity).\n"
     ]
    }
   ],
   "source": [
    "### 2. Check for Equal Variances using Levene’s Test\n",
    "print(\"\\nVariance Test (Levene's Test)\")\n",
    "stat, p_value_levene = stats.levene(gate_30, gate_40)\n",
    "print(f\"Levene’s test statistic: {stat}, p-value: {p_value_levene}\")\n",
    "\n",
    "if p_value_levene < 0.05:\n",
    "    print(\"Variances are not equal (heteroscedasticity). Use Welch's t-test or non-parametric tests.\")\n",
    "else:\n",
    "    print(\"Variances are equal (homoscedasticity).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5389936e-4b31-41f7-9807-626959d3f075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard t-test result: t-statistic=0.8910426211362967, p-value=0.37290868247405207\n"
     ]
    }
   ],
   "source": [
    "### 3. Perform T-test or Welch's T-test\n",
    "# Check if normality and variance assumptions are met\n",
    "if p_value_levene > 0.05:\n",
    "        # Use standard t-test (equal variances)\n",
    "        t_stat, p_val_ttest = stats.ttest_ind(gate_30, gate_40, equal_var=True)\n",
    "        print(f\"Standard t-test result: t-statistic={t_stat}, p-value={p_val_ttest}\")\n",
    "else:\n",
    "    # Use Welch's t-test (unequal variances)\n",
    "    t_stat, p_val_ttest = stats.ttest_ind(gate_30, gate_40, equal_var=False)\n",
    "    print(f\"Welch's t-test result: t-statistic={t_stat}, p-value={p_val_ttest}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0be1100c-03c1-49de-b6b3-2cf6efb10160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mann-Whitney U Test result: U-statistic=1024331250.5, p-value=0.05020880772044255\n"
     ]
    }
   ],
   "source": [
    "### 4. If Normality Violated, Perform Non-Parametric Mann-Whitney U Test\n",
    "\n",
    "# Non-parametric Mann-Whitney U test\n",
    "u_stat, p_val_mw = stats.mannwhitneyu(gate_30, gate_40, alternative='two-sided')\n",
    "print(f\"Mann-Whitney U Test result: U-statistic={u_stat}, p-value={p_val_mw}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aaf853a-d5e6-4c71-87e8-343dccf55cfc",
   "metadata": {},
   "source": [
    "If the p-value from the Mann-Whitney U test is greater than 0.05, it means that there is no statistically significant difference between the distributions of the sum_gamerounds for the two versions (Gate_30 and Gate_40).\n",
    "\n",
    "**Here's how you can interpret the result:<br/>**\n",
    "- Null Hypothesis (H₀): The distributions of sum_gamerounds for Gate_30 and Gate_40 are the same. <br/>\n",
    "- Alternative Hypothesis (H₁): The distributions of sum_gamerounds for Gate_30 and Gate_40 are different. <br/>\n",
    "Since the p-value is greater than 0.05, you fail to reject the null hypothesis, meaning that there is no strong evidence to suggest that the two versions (Gate_30 and Gate_40) result in different distributions of sum_gamerounds.\n",
    "\n",
    "**Conclusion:**\n",
    "The Mann-Whitney U test suggests that there is no significant difference in the number of game rounds played between users in the Gate_30 and Gate_40 groups.\n",
    "\n",
    "**Practical Interpretation:**\n",
    "This result implies that changing the version from Gate_30 to Gate_40 likely does not have a notable impact on the total number of game rounds played by users. Based on this test, you might conclude that the change in the version (from Gate_30 to Gate_40) does not affect user engagement, as measured by sum_gamerounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248c9ab7-8aea-4a0a-9bd1-4ef919af36f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f3057c-9391-4614-b3fe-ccd01f1ee92c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
